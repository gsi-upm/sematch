{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook records the experiments I have done in the article of \"Computing Semantic Similarity of Concepts in Knowledge Graphs\". If someone is interested in reproducing the experiments, one can install Sematch and use this notebook for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sematch.semantic.similarity import WordNetSimilarity\n",
    "from IPython.display import display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple example of word similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wns = WordNetSimilarity()\n",
    "words = ['artist', 'musician', 'scientist', 'physicist', 'actor', 'movie']\n",
    "sim_matrix = [[wns.word_similarity(w1, w2, 'wpath') for w1 in words] for w2 in words]\n",
    "df = pd.DataFrame(sim_matrix, index=words,columns=words)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluations on Word Similarity Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have collected some well known word similarity datasets for evaluating semantic similarity metrics. Several python classes can be used to separate the dataset for specicial purpose and evaluate the metric function automatically. \n",
    "\n",
    "We put them together and provide a uniformed framework to evaluate different semantic measures. The word similarity datasets include:\n",
    "\n",
    "- [Rubenstein and Goodenough (RG)](http://www.cs.cmu.edu/~mfaruqui/word-sim/EN-RG-65.txt) \n",
    "\n",
    "Herbert Rubenstein and John B. Goodenough. 1965. Contextual correlates of synonymy. Commun. ACM 8, 10 (October 1965), 627-633. DOI=10.1145/365628.365657 \n",
    "\n",
    "- [Miller and Charles (MC)](http://www.cs.cmu.edu/~mfaruqui/word-sim/EN-MC-30.txt) \n",
    "\n",
    "Miller, George A., and Walter G. Charles. \"Contextual correlates of semantic similarity.\" Language and cognitive processes 6.1 (1991): 1-28.\n",
    "\n",
    "- [Wordsim353 (WS353)](http://www.cs.technion.ac.il/~gabr/resources/data/wordsim353/) \n",
    "\n",
    "Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias, Ehud Rivlin, Zach Solan, Gadi Wolfman, and Eytan Ruppin, \"Placing Search in Context: The Concept Revisited\", ACM Transactions on Information Systems, 20(1):116-131, January 2002 \n",
    "\n",
    "- [wordsim353 similarity and relatedness (WS353Sim)](http://alfonseca.org/eng/research/wordsim353.html) \n",
    "\n",
    "Eneko Agirre, Enrique Alfonseca, Keith Hall, Jana Kravalova, Marius Pasca, Aitor Soroa, A Study on Similarity and Relatedness Using Distributional and WordNet-based Approaches, In Proceedings of NAACL-HLT 2009.\n",
    "\n",
    "- [SimLex-999 (SIMLEX)](http://www.cl.cam.ac.uk/~fh295/simlex.html) \n",
    "\n",
    "SimLex-999: Evaluating Semantic Models with (Genuine) Similarity Estimation. 2014. Felix Hill, Roi Reichart and Anna Korhonen. Preprint pubslished on arXiv. arXiv:1408.3456\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sematch.evaluation import WordSimEvaluation\n",
    "from sematch.semantic.similarity import WordNetSimilarity, YagoTypeSimilarity\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "data_word_noun = ['noun_rg','noun_mc','noun_ws353','noun_ws353-sim','noun_simlex']\n",
    "data_word_graph = ['graph_rg','graph_mc','graph_ws353','graph_ws353-sim','graph_simlex']\n",
    "data_word_type = ['type_rg','type_mc','type_ws353','type_ws353-sim','type_simlex']\n",
    "\n",
    "sim_methods_noun = ['path','lch','wup','li','res','lin','jcn','wpath']\n",
    "sim_methods_graph = ['path','lch','wup','li','res','res_graph','lin','jcn','wpath','wpath_graph']\n",
    "sim_methods_type = ['path','lch','wup','li','res','res_graph','lin','lin_graph','jcn','jcn_graph','wpath','wpath_graph']\n",
    "\n",
    "ws_eval = WordSimEvaluation()\n",
    "wns = WordNetSimilarity()\n",
    "yagosim = YagoTypeSimilarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To produce the TABLE 2 in the article \"The illustration of Semantic Similarity Methods on Some Concept Pair Examples\". We manually create the word to synset mapping and compute their semantic similarity scores using different semantic similarity metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = {'beef':wn.synset('beef.n.02'), 'lamb':wn.synset('lamb.n.05'), 'octopus':wn.synset('octopus.n.01'),\n",
    "          'shellfish':wn.synset('shellfish.n.01'), 'meat':wn.synset('meat.n.01'), 'seafood':wn.synset('seafood.n.01'),\n",
    "          'food':wn.synset('food.n.02'), 'service':wn.synset('service.n.02'),'atmosphere':wn.synset('atmosphere.n.01'),\n",
    "          'coffee':wn.synset('coffee.n.01')}\n",
    "aspect_pairs = [('beef', 'octopus'), ('beef', 'lamb'), ('meat','seafood'), ('octopus', 'shellfish'),\n",
    "               ('beef','service'),('beef','atmosphere'),('beef', 'coffee'), ('food','coffee')]\n",
    "aspects_sim_matrix = [[wns.similarity(aspects[w1], aspects[w2], m) for m in sim_methods_noun] \n",
    "                      for w1, w2 in aspect_pairs]\n",
    "aspect_index = [x+'-'+y for x, y in aspect_pairs]\n",
    "aspect_df = pd.DataFrame(aspects_sim_matrix, index=aspect_index, columns=sim_methods_noun)\n",
    "display(aspect_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WPATH method with different K in Word Noun Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data_word_noun contains word pairs that can be mapped to WordNet noun taxonomy. The k settings are varied with interval 0.1 started from 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpath_cors = [ws_eval.evaluate_wpath_k(dataset) for _, dataset in enumerate(data_word_noun)]\n",
    "cors_matrix = [[cors[i] for _, cors in enumerate(wpath_cors)] for i in range(1,11)]\n",
    "wpath_index = map(lambda x: str(x/10.0), range(1, 11))\n",
    "df_wpath = pd.DataFrame(cors_matrix, index=wpath_index, columns=data_word_noun)\n",
    "display(df_wpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WPATH method with different K in Word Graph Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In word graph dataset, we performed the evaluation of wpath with different k using corpus-based IC and graph-based IC respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate with corpus-based IC\n",
    "wpath_cors = [ws_eval.evaluate_wpath_k(dataset) for _, dataset in enumerate(data_word_graph)]\n",
    "cors_matrix = [[cors[i] for _, cors in enumerate(wpath_cors)] for i in range(1,11)]\n",
    "df_wpath_graph = pd.DataFrame(cors_matrix, index=wpath_index, columns=data_word_graph)\n",
    "display(df_wpath_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate with graph-based IC\n",
    "wpath_cors = [ws_eval.evaluate_wpath_k(dataset, 'graph') for _, dataset in enumerate(data_word_graph)]\n",
    "cors_matrix = [[cors[i] for _, cors in enumerate(wpath_cors)] for i in range(1,11)]\n",
    "df_wpath_graph = pd.DataFrame(cors_matrix, index=wpath_index, columns=data_word_graph)\n",
    "display(df_wpath_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WPATH method with different K in Word Type Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate with corpus-based IC\n",
    "wpath_cors = [ws_eval.evaluate_wpath_k(dataset) for _, dataset in enumerate(data_word_type)]\n",
    "cors_matrix = [[cors[i] for _, cors in enumerate(wpath_cors)] for i in range(1,11)]\n",
    "df_wpath_type = pd.DataFrame(cors_matrix, index=wpath_index, columns=data_word_type)\n",
    "display(df_wpath_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate with graph-based IC\n",
    "wpath_cors = [ws_eval.evaluate_wpath_k(dataset, 'graph') for _, dataset in enumerate(data_word_type)]\n",
    "cors_matrix = [[cors[i] for _, cors in enumerate(wpath_cors)] for i in range(1,11)]\n",
    "df_wpath_type = pd.DataFrame(cors_matrix, index=wpath_index, columns=data_word_type)\n",
    "display(df_wpath_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline semantic similarity metrics on Word Noun Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = lambda x, y: wns.word_similarity(x, y, 'path')\n",
    "lch = lambda x, y: wns.word_similarity(x, y, 'lch')\n",
    "wup = lambda x, y: wns.word_similarity(x, y, 'wup')\n",
    "li = lambda x, y: wns.word_similarity(x, y, 'li')\n",
    "res = lambda x, y: wns.word_similarity(x, y, 'res')\n",
    "lin = lambda x, y: wns.word_similarity(x, y, 'lin')\n",
    "jcn = lambda x, y: wns.word_similarity(x, y, 'jcn')\n",
    "\n",
    "methods = {'path':path, 'lch':lch, 'wup':wup, 'li':li, 'res':res, 'lin':lin, 'jcn':jcn}\n",
    "cor_dicts = [ws_eval.evaluate_multiple_metrics(methods, dataset) for dataset in data_word_noun]\n",
    "baseline_cors_matrix = [[cors[m] for _, cors in enumerate(cor_dicts)] for m in sim_methods_noun[0:7]]\n",
    "df_baselines_noun = pd.DataFrame(baseline_cors_matrix, index=sim_methods_noun[0:7], columns=data_word_noun)\n",
    "display(df_baselines_noun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline semantic similarity metrics on Word Graph Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_graph = lambda x, y: yagosim.word_similarity(x, y, 'res_graph')\n",
    "methods['res_graph'] = res_graph\n",
    "cor_dicts = [ws_eval.evaluate_multiple_metrics(methods, dataset) for dataset in data_word_graph]\n",
    "baseline_cors_matrix = [[cors[m] for _, cors in enumerate(cor_dicts)] for m in sim_methods_graph[0:8]]\n",
    "df_baselines_graph = pd.DataFrame(baseline_cors_matrix, index=sim_methods_graph[0:8], columns=data_word_graph)\n",
    "display(df_baselines_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline semantic similarity metrics on Word Type Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_graph = lambda x, y: yagosim.word_similarity(x, y, 'lin_graph')\n",
    "jcn_graph = lambda x, y: yagosim.word_similarity(x, y, 'jcn_graph')\n",
    "methods['lin_graph'] = lin_graph\n",
    "methods['jcn_graph'] = jcn_graph\n",
    "cor_dicts = [ws_eval.evaluate_multiple_metrics(methods, dataset) for dataset in data_word_type]\n",
    "baseline_cors_matrix = [[cors[m] for _, cors in enumerate(cor_dicts)] for m in sim_methods_type[0:10]]\n",
    "df_baselines_type = pd.DataFrame(baseline_cors_matrix, index=sim_methods_type[0:10], columns=data_word_type)\n",
    "display(df_baselines_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steiger's Z Significance Test on Word Noun Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpath_rg = lambda x, y: wns.word_similarity_wpath(x, y, 0.9)\n",
    "wpath_mc = lambda x, y: wns.word_similarity_wpath(x, y, 0.4)\n",
    "wpath_ws353 = lambda x, y: wns.word_similarity_wpath(x, y, 0.5)\n",
    "wpath_ws353sim = lambda x, y: wns.word_similarity_wpath(x, y, 0.8)\n",
    "wpath_simlex = lambda x, y: wns.word_similarity_wpath(x, y, 0.8)\n",
    "\n",
    "methods = {'wpath_rg':wpath_rg, 'wpath_mc':wpath_mc, 'wpath_ws353':wpath_ws353, \n",
    "           'wpath_ws353sim':wpath_ws353sim,'wpath_simlex':wpath_simlex}\n",
    "\n",
    "cor_dicts = [ws_eval.evaluate_multiple_metrics(methods, dataset) for dataset in data_word_noun]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpath_dic = {'noun_rg':'wpath_rg', 'noun_mc':'wpath_mc', 'noun_ws353':'wpath_ws353',\n",
    "            'noun_ws353-sim':'wpath_ws353sim', 'noun_simlex':'wpath_simlex'}\n",
    "\n",
    "cors_matrix = [[cor_dicts[i][wpath_dic[dataset]] for i, dataset in enumerate(data_word_noun)]]\n",
    "df_cors = pd.DataFrame(cors_matrix, index=['metrics'], columns=data_word_noun)\n",
    "display(df_cors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the Steiger's Z Significance Test, one can use the implementation integrated in Sematch framework, or use the R, cocor package. The example scripts using cocor package to perform statistical test in Simlex dataset is shown as:\n",
    "```\n",
    "require(cocor) # load package\n",
    "#j means dependent sample, k and h means comparison sample\n",
    "#we have wpath with human (jk), jcn with human (jh), and wpath with jcn (kh)\n",
    "#simlex\n",
    "#wpath with path Pass\n",
    "cocor.dep.groups.overlap(r.jk=+0.603, r.jh=+0.584, r.kh=+0.955, n=666, alternative=\"greater\", alpha=0.05, conf.level=0.95, null.value=0)\n",
    "#wpath with lch Pass\n",
    "cocor.dep.groups.overlap(r.jk=+0.603, r.jh=+0.584, r.kh=+0.955, n=666, alternative=\"greater\", alpha=0.05, conf.level=0.95, null.value=0)\n",
    "#wpath with wup Pass\n",
    "cocor.dep.groups.overlap(r.jk=+0.603, r.jh=+0.542, r.kh=+0.946, n=666, alternative=\"greater\", alpha=0.05, conf.level=0.95, null.value=0)\n",
    "#wpath with li Pass\n",
    " cocor.dep.groups.overlap(r.jk=+0.603, r.jh=+0.586, r.kh=+0.965, n=666, alternative=\"greater\", alpha=0.05, conf.level=0.95, null.value=0)\n",
    "#wpath with res Pass\n",
    "cocor.dep.groups.overlap(r.jk=+0.603, r.jh=+0.535, r.kh=+0.913, n=666, alternative=\"greater\", alpha=0.05, conf.level=0.95, null.value=0)\n",
    "#wpath with lin Pass\n",
    "cocor.dep.groups.overlap(r.jk=+0.603, r.jh=+0.582, r.kh=+0.944, n=666, alternative=\"greater\", alpha=0.05, conf.level=0.95, null.value=0)\n",
    "```\n",
    "The example of using the integrated Statistical Test is illustrate in the following codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_tests = []\n",
    "for _, dataset in enumerate(data_word_noun):\n",
    "    stats = {}\n",
    "    for _, m in enumerate(sim_methods_noun[0:7]):\n",
    "        cor, p_value = ws_eval.statistical_test(wpath_dic[dataset], m, dataset)\n",
    "        stats[m] = '('+str(round(cor,3))+','+str(p_value)+')'\n",
    "    stats_tests.append(stats)\n",
    "stats_matrix = [[cors[m] for _, cors in enumerate(stats_tests)] for _, m in enumerate(sim_methods_noun[0:7])]\n",
    "df_stats = pd.DataFrame(stats_matrix, index=sim_methods_noun[0:7], columns=data_word_noun)\n",
    "display(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"gsutil -m cp gs://nis-dataproc/data/follow-unfollow/namedEntities.p ./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "namedEntities = pickle.load(open(\"namedEntities.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, dbpedia_urls = zip(*[(t[1]['name'], t[1]['dbpedia_url']) for t in namedEntities.iteritems()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names_pairs = [(n1, n2) for n1 in names for n2 in names]\n",
    "all_urls_pairs = [(n1, n2) for n1 in dbpedia_urls for n2 in dbpedia_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Dineshwar_Sharma', u'Dineshwar_Sharma'),\n",
       " (u'Dineshwar_Sharma', u'Cairn_India'),\n",
       " (u'Dineshwar_Sharma', u'McKinsey_%26_Company'),\n",
       " (u'Dineshwar_Sharma', u'Intercontinental_ballistic_missile')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_names_pairs[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'http://dbpedia.org/resource/Dineshwar_Sharma',\n",
       "  u'http://dbpedia.org/resource/Dineshwar_Sharma'),\n",
       " (u'http://dbpedia.org/resource/Dineshwar_Sharma',\n",
       "  u'http://dbpedia.org/resource/Cairn_India'),\n",
       " (u'http://dbpedia.org/resource/Dineshwar_Sharma',\n",
       "  u'http://dbpedia.org/resource/McKinsey_%26_Company'),\n",
       " (u'http://dbpedia.org/resource/Dineshwar_Sharma',\n",
       "  u'http://dbpedia.org/resource/Intercontinental_ballistic_missile')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_urls_pairs[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.000034\n"
     ]
    }
   ],
   "source": [
    "from sematch.semantic.similarity import EntitySimilarity\n",
    "sim = EntitySimilarity()\n",
    "import datetime\n",
    "st = datetime.datetime.now()\n",
    "# print sim.similarity('http://dbpedia.org/resource/Madrid','http://dbpedia.org/resource/Barcelona') #0.409923677282\n",
    "# print sim.similarity('http://dbpedia.org/resource/Narendra_Modi','http://dbpedia.org/resource/Steve_Jobs')#0.0904545454545\n",
    "# print sim.relatedness('http://dbpedia.org/resource/Madrid','http://dbpedia.org/resource/Barcelona')#0.457984139871\n",
    "# print sim.relatedness('http://dbpedia.org/resource/Arun_Jaitley', 'http://dbpedia.org/resource/Narendra_Modi')#0.465991132787\n",
    "en = datetime.datetime.now()\n",
    "print en - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.902403335865\n",
      "0.986416248169\n",
      "0.930793437854\n",
      "0:00:09.498396\n"
     ]
    }
   ],
   "source": [
    "st = datetime.datetime.now()\n",
    "print sim.di_relatedness('http://dbpedia.org/resource/Cristiano_Ronaldo','http://dbpedia.org/resource/Madrid')#0.457984139871\n",
    "print sim.di_relatedness('http://dbpedia.org/resource/Arun_Jaitley', 'http://dbpedia.org/resource/Narendra_Modi')#0.465991132787\n",
    "print sim.di_relatedness('http://dbpedia.org/resource/Sachin_Tendulkar', 'http://dbpedia.org/resource/Cricket')\n",
    "en = datetime.datetime.now()\n",
    "print en - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.384560921554\n",
      "0.788008763981\n",
      "0.21519414076\n",
      "0:00:02.233770\n"
     ]
    }
   ],
   "source": [
    "st = datetime.datetime.now()\n",
    "print sim.di_relatedness('http://dbpedia.org/resource/Madrid','http://dbpedia.org/resource/Cristiano_Ronaldo')#0.457984139871\n",
    "print sim.di_relatedness('http://dbpedia.org/resource/Narendra_Modi', 'http://dbpedia.org/resource/Arun_Jaitley')#0.465991132787\n",
    "print sim.di_relatedness('http://dbpedia.org/resource/Cricket', 'http://dbpedia.org/resource/Sachin_Tendulkar')\n",
    "en = datetime.datetime.now()\n",
    "print en - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640476618239\n",
      "0:00:01.540255\n"
     ]
    }
   ],
   "source": [
    "st = datetime.datetime.now()\n",
    "print sim.di_relatedness('http://dbpedia.org/resource/Sachin_Tendulkar', 'http://dbpedia.org/resource/Narendra_Modi')\n",
    "en = datetime.datetime.now()\n",
    "print en - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.149850346799\n",
      "0:00:01.638156\n"
     ]
    }
   ],
   "source": [
    "st = datetime.datetime.now()\n",
    "print sim.di_relatedness('http://dbpedia.org/resource/Cricket', 'http://dbpedia.org/resource/Narendra_Modi')\n",
    "en = datetime.datetime.now()\n",
    "print en - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.149850346799\n",
      "0:00:02.235042\n"
     ]
    }
   ],
   "source": [
    "st = datetime.datetime.now()\n",
    "print sim.di_relatedness('http://dbpedia.org/resource/Cricket', 'http://dbpedia.org/resource/Madrid')\n",
    "en = datetime.datetime.now()\n",
    "print en - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.07704736658\n",
      "1.01002662437\n",
      "0.442058902002\n",
      "0:00:02.734767\n"
     ]
    }
   ],
   "source": [
    "st = datetime.datetime.now()\n",
    "print sim.di_relatedness('http://dbpedia.org/resource/Bharatiya_Janata_Party', 'http://dbpedia.org/resource/Bharatiya_Janata_Party')\n",
    "print sim.di_relatedness('http://dbpedia.org/resource/Rahul_Gandhi', 'http://dbpedia.org/resource/Indian_National_Congress')\n",
    "print sim.di_relatedness('http://dbpedia.org/resource/Indian_National_Congress', 'http://dbpedia.org/resource/Rahul_Gandhi')\n",
    "en = datetime.datetime.now()\n",
    "print en - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
